# Local GPT-OSS 20B Setup Guide

ì´ ê°€ì´ë“œëŠ” ë¡œì»¬ GPU 0, 1ë²ˆì—ì„œ GPT-OSS 20Bë¥¼ ì‹¤í–‰í•˜ê³  ARC ì‹¤í—˜ì„ ì§„í–‰í•˜ëŠ” ë°©ë²•ì„ ì„¤ëª…í•©ë‹ˆë‹¤.

## ğŸ“‹ êµ¬í˜„ ì™„ë£Œ ì‚¬í•­

### 1. ì½”ë“œ ìˆ˜ì •
- âœ… `src/llms/models.py`: `local_gpt_oss_20b` ëª¨ë¸ ì¶”ê°€
- âœ… `src/llms/structured.py`: ë¡œì»¬ vLLM ì„œë²„ í˜¸ì¶œ í•¨ìˆ˜ ì¶”ê°€
- âœ… `src/configs/oss_configs.py`: `local_gpt_oss_20b_config` ì„¤ì • ì¶”ê°€
- âœ… `src/run.py`: `/data/arclang` ê²½ë¡œ ì„¤ì • ë° `local_gpt_oss_20b_config` ì‚¬ìš©

### 2. ë””ë ‰í† ë¦¬ êµ¬ì¡°
```
/data/arclang/
â”œâ”€â”€ logs/              # vLLM ì„œë²„ ë¡œê·¸
â”œâ”€â”€ checkpoints/       # ì²´í¬í¬ì¸íŠ¸
â””â”€â”€ attempts/          # ARC ì‹¤í—˜ ê²°ê³¼
    â””â”€â”€ arc-prize-2024/
```

## ğŸš€ ì‚¬ìš© ë°©ë²•

### Step 1: vLLM ì„œë²„ ì‹œì‘

**í„°ë¯¸ë„ 1ì—ì„œ ì‹¤í–‰:**
```bash
cd /home/ubuntu/arc-lang-public
./start_vllm_server.sh
```

ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ”:
- vLLMì„ ìë™ ì„¤ì¹˜ (í•„ìš”ì‹œ)
- GPU 0, 1ì—ì„œ tensor parallelë¡œ GPT-OSS 20B ì„œë²„ ì‹œì‘
- í¬íŠ¸ 8000ì—ì„œ OpenAI API í˜¸í™˜ ì„œë²„ ì‹¤í–‰
- ë¡œê·¸ë¥¼ `/data/arclang/logs/` ì— ì €ì¥

**ì„œë²„ê°€ ì¤€ë¹„ë˜ë©´ ë‹¤ìŒê³¼ ê°™ì€ ë©”ì‹œì§€ê°€ í‘œì‹œë©ë‹ˆë‹¤:**
```
INFO:     Uvicorn running on http://0.0.0.0:8000
```

### Step 2: ARC ì‹¤í—˜ ì‹¤í–‰

**í„°ë¯¸ë„ 2ì—ì„œ ì‹¤í–‰:**
```bash
cd /home/ubuntu/arc-lang-public
export MAX_CONCURRENCY=20
export LOCAL_VLLM_URL="http://localhost:8000/v1"  # ê¸°ë³¸ê°’ì´ë¯€ë¡œ ìƒëµ ê°€ëŠ¥
python src/run.py
```

## ğŸ”§ í™˜ê²½ ë³€ìˆ˜

í•„ìš”í•œ í™˜ê²½ ë³€ìˆ˜ë¥¼ `.env` íŒŒì¼ì— ì¶”ê°€í•˜ì„¸ìš”:

```bash
# ê¸°ì¡´ í™˜ê²½ ë³€ìˆ˜ë“¤...
MAX_CONCURRENCY=20

# ë¡œì»¬ vLLM ì„œë²„ URL (ì„ íƒì‚¬í•­, ê¸°ë³¸ê°’: http://localhost:8000/v1)
LOCAL_VLLM_URL=http://localhost:8000/v1
```

## ğŸ“Š í˜„ì¬ ì„¤ì •

`src/run.py` ì˜ í˜„ì¬ ì„¤ì •:
- **Config**: `local_gpt_oss_20b_config`
- **Dataset**: ARC 2024 evaluation
- **Limit**: 1 task (í…ŒìŠ¤íŠ¸ìš©)
- **Offset**: 0

ì‹¤ì œ ì‹¤í—˜ì„ ìœ„í•´ `src/run.py`ì˜ `limit` ê°’ì„ ì¡°ì •í•˜ì„¸ìš”:
```python
await run_from_json(
    challenges_path=challenges_path,
    truth_solutions_path=solutions_path,
    config=local_gpt_oss_20b_config,
    attempts_path=attempts_path,
    temp_attempts_dir=temp_attempts_path,
    limit=None,  # ì „ì²´ ë°ì´í„°ì…‹
    offset=0,
)
```

## ğŸ” ëª¨ë‹ˆí„°ë§

### vLLM ì„œë²„ ë¡œê·¸ í™•ì¸
```bash
tail -f /data/arclang/logs/vllm_server_*.log
```

### GPU ì‚¬ìš©ë¥  í™•ì¸
```bash
watch -n 1 nvidia-smi
```

### ì‹¤í—˜ ê²°ê³¼ í™•ì¸
```bash
ls -lh /data/arclang/attempts/arc-prize-2024/
```

## ğŸ› ï¸ íŠ¸ëŸ¬ë¸”ìŠˆíŒ…

### vLLM ì„œë²„ê°€ ì‹œì‘ë˜ì§€ ì•Šì„ ë•Œ
1. GPU ë©”ëª¨ë¦¬ í™•ì¸: `nvidia-smi`
2. í¬íŠ¸ ì‚¬ìš© í™•ì¸: `netstat -tlnp | grep 8000`
3. ë¡œê·¸ í™•ì¸: `tail -f /data/arclang/logs/vllm_server_*.log`

### ì—°ê²° ì˜¤ë¥˜ê°€ ë°œìƒí•  ë•Œ
1. vLLM ì„œë²„ê°€ ì‹¤í–‰ ì¤‘ì¸ì§€ í™•ì¸
2. `LOCAL_VLLM_URL` í™˜ê²½ ë³€ìˆ˜ í™•ì¸
3. ë°©í™”ë²½ ì„¤ì • í™•ì¸

### Out of Memory ì˜¤ë¥˜
`start_vllm_server.sh`ì—ì„œ `--gpu-memory-utilization` ê°’ì„ ë‚®ì¶”ì„¸ìš”:
```bash
--gpu-memory-utilization 0.8  # ê¸°ë³¸ê°’ 0.95ì—ì„œ 0.8ë¡œ ë³€ê²½
```

## ğŸ“ ê¸°ìˆ  ì„¸ë¶€ì‚¬í•­

### vLLM vs Transformers ì§ì ‘ ì‚¬ìš©
vLLMì„ ì„ íƒí•œ ì´ìœ :
- **24ë°° ë¹ ë¥¸ ì²˜ë¦¬ëŸ‰** (2025 ë²¤ì¹˜ë§ˆí¬)
- **ë°°ì¹˜ ì²˜ë¦¬ ìµœì í™”**: PagedAttentionìœ¼ë¡œ ë©”ëª¨ë¦¬ íš¨ìœ¨ì 
- **OpenAI API í˜¸í™˜**: ìµœì†Œí•œì˜ ì½”ë“œ ë³€ê²½
- **Tensor Parallel ì§€ì›**: GPU 0, 1 ë™ì‹œ í™œìš©

### ëª¨ë¸ ì •ë³´
- **Model**: `openai/gpt-oss-20b`
- **Parameters**: 21B (MoE, 3.6B active)
- **Quantization**: MXFP4 (4-bit)
- **ë©”ëª¨ë¦¬**: ~16GB (GPUë‹¹ ì¶©ë¶„íˆ ì—¬ìœ )

## ğŸ”„ ê¸°ì¡´ OpenRouter ì„¤ì •ê³¼ì˜ ë¹„êµ

ê¸°ì¡´ OpenRouter GPT-OSS 120B ì„¤ì •ì€ ê·¸ëŒ€ë¡œ ìœ ì§€ë©ë‹ˆë‹¤:
- `oss_config`: OpenRouterë¥¼ í†µí•œ GPT-OSS 120B
- `local_gpt_oss_20b_config`: ë¡œì»¬ vLLMì„ í†µí•œ GPT-OSS 20B

í•„ìš”ì— ë”°ë¼ `src/run.py`ì—ì„œ configë¥¼ ë³€ê²½í•˜ì—¬ ì‚¬ìš©í•˜ì„¸ìš”.
